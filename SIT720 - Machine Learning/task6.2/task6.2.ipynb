{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c116aeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Status</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>D</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>21464</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>14.5</td>\n",
       "      <td>261.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1718.0</td>\n",
       "      <td>137.95</td>\n",
       "      <td>172.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4500</td>\n",
       "      <td>C</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>20617</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1.1</td>\n",
       "      <td>302.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7394.8</td>\n",
       "      <td>113.52</td>\n",
       "      <td>88.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1012</td>\n",
       "      <td>D</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>25594</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>S</td>\n",
       "      <td>1.4</td>\n",
       "      <td>176.0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>210.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>96.10</td>\n",
       "      <td>55.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1925</td>\n",
       "      <td>D</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>19994</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>S</td>\n",
       "      <td>1.8</td>\n",
       "      <td>244.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6121.8</td>\n",
       "      <td>60.63</td>\n",
       "      <td>92.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1504</td>\n",
       "      <td>CL</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>13918</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3.4</td>\n",
       "      <td>279.0</td>\n",
       "      <td>3.53</td>\n",
       "      <td>143.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>113.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  N_Days Status             Drug    Age Sex Ascites Hepatomegaly Spiders  \\\n",
       "0   1     400      D  D-penicillamine  21464   F       Y            Y       Y   \n",
       "1   2    4500      C  D-penicillamine  20617   F       N            Y       Y   \n",
       "2   3    1012      D  D-penicillamine  25594   M       N            N       N   \n",
       "3   4    1925      D  D-penicillamine  19994   F       N            Y       Y   \n",
       "4   5    1504     CL          Placebo  13918   F       N            Y       Y   \n",
       "\n",
       "  Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n",
       "0     Y       14.5        261.0     2.60   156.0    1718.0  137.95   \n",
       "1     N        1.1        302.0     4.14    54.0    7394.8  113.52   \n",
       "2     S        1.4        176.0     3.48   210.0     516.0   96.10   \n",
       "3     S        1.8        244.0     2.54    64.0    6121.8   60.63   \n",
       "4     N        3.4        279.0     3.53   143.0     671.0  113.15   \n",
       "\n",
       "   Tryglicerides  Platelets  Prothrombin  Stage  \n",
       "0          172.0      190.0         12.2    4.0  \n",
       "1           88.0      221.0         10.6    3.0  \n",
       "2           55.0      151.0         12.0    4.0  \n",
       "3           92.0      183.0         10.3    4.0  \n",
       "4           72.0      136.0         10.9    3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (418, 20)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   ID             418 non-null    int64  \n",
      " 1   N_Days         418 non-null    int64  \n",
      " 2   Status         418 non-null    object \n",
      " 3   Drug           312 non-null    object \n",
      " 4   Age            418 non-null    int64  \n",
      " 5   Sex            418 non-null    object \n",
      " 6   Ascites        312 non-null    object \n",
      " 7   Hepatomegaly   312 non-null    object \n",
      " 8   Spiders        312 non-null    object \n",
      " 9   Edema          418 non-null    object \n",
      " 10  Bilirubin      418 non-null    float64\n",
      " 11  Cholesterol    284 non-null    float64\n",
      " 12  Albumin        418 non-null    float64\n",
      " 13  Copper         310 non-null    float64\n",
      " 14  Alk_Phos       312 non-null    float64\n",
      " 15  SGOT           312 non-null    float64\n",
      " 16  Tryglicerides  282 non-null    float64\n",
      " 17  Platelets      407 non-null    float64\n",
      " 18  Prothrombin    416 non-null    float64\n",
      " 19  Stage          412 non-null    float64\n",
      "dtypes: float64(10), int64(3), object(7)\n",
      "memory usage: 65.4+ KB\n",
      "\n",
      "Missing values per column:\n",
      "ID                 0\n",
      "N_Days             0\n",
      "Status             0\n",
      "Drug             106\n",
      "Age                0\n",
      "Sex                0\n",
      "Ascites          106\n",
      "Hepatomegaly     106\n",
      "Spiders          106\n",
      "Edema              0\n",
      "Bilirubin          0\n",
      "Cholesterol      134\n",
      "Albumin            0\n",
      "Copper           108\n",
      "Alk_Phos         106\n",
      "SGOT             106\n",
      "Tryglicerides    136\n",
      "Platelets         11\n",
      "Prothrombin        2\n",
      "Stage              6\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Status</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418</td>\n",
       "      <td>312</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>418</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>412.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>D-penicillamine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232</td>\n",
       "      <td>158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "      <td>288</td>\n",
       "      <td>160</td>\n",
       "      <td>222</td>\n",
       "      <td>354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>209.500000</td>\n",
       "      <td>1917.782297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18533.351675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.220813</td>\n",
       "      <td>369.510563</td>\n",
       "      <td>3.497440</td>\n",
       "      <td>97.648387</td>\n",
       "      <td>1982.655769</td>\n",
       "      <td>122.556346</td>\n",
       "      <td>124.702128</td>\n",
       "      <td>257.024570</td>\n",
       "      <td>10.731731</td>\n",
       "      <td>3.024272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>1104.672992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3815.845055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.407506</td>\n",
       "      <td>231.944545</td>\n",
       "      <td>0.424972</td>\n",
       "      <td>85.613920</td>\n",
       "      <td>2140.388824</td>\n",
       "      <td>56.699525</td>\n",
       "      <td>65.148639</td>\n",
       "      <td>98.325585</td>\n",
       "      <td>1.022000</td>\n",
       "      <td>0.882042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9598.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>26.350000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>105.250000</td>\n",
       "      <td>1092.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15644.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>249.500000</td>\n",
       "      <td>3.242500</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>871.500000</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>84.250000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>209.500000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18628.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>309.500000</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1259.000000</td>\n",
       "      <td>114.700000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>313.750000</td>\n",
       "      <td>2613.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21272.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>151.900000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>4795.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28650.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1775.000000</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>13862.400000</td>\n",
       "      <td>457.250000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>721.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID       N_Days Status             Drug           Age  Sex  \\\n",
       "count   418.000000   418.000000    418              312    418.000000  418   \n",
       "unique         NaN          NaN      3                2           NaN    2   \n",
       "top            NaN          NaN      C  D-penicillamine           NaN    F   \n",
       "freq           NaN          NaN    232              158           NaN  374   \n",
       "mean    209.500000  1917.782297    NaN              NaN  18533.351675  NaN   \n",
       "std     120.810458  1104.672992    NaN              NaN   3815.845055  NaN   \n",
       "min       1.000000    41.000000    NaN              NaN   9598.000000  NaN   \n",
       "25%     105.250000  1092.750000    NaN              NaN  15644.500000  NaN   \n",
       "50%     209.500000  1730.000000    NaN              NaN  18628.000000  NaN   \n",
       "75%     313.750000  2613.500000    NaN              NaN  21272.500000  NaN   \n",
       "max     418.000000  4795.000000    NaN              NaN  28650.000000  NaN   \n",
       "\n",
       "       Ascites Hepatomegaly Spiders Edema   Bilirubin  Cholesterol  \\\n",
       "count      312          312     312   418  418.000000   284.000000   \n",
       "unique       2            2       2     3         NaN          NaN   \n",
       "top          N            Y       N     N         NaN          NaN   \n",
       "freq       288          160     222   354         NaN          NaN   \n",
       "mean       NaN          NaN     NaN   NaN    3.220813   369.510563   \n",
       "std        NaN          NaN     NaN   NaN    4.407506   231.944545   \n",
       "min        NaN          NaN     NaN   NaN    0.300000   120.000000   \n",
       "25%        NaN          NaN     NaN   NaN    0.800000   249.500000   \n",
       "50%        NaN          NaN     NaN   NaN    1.400000   309.500000   \n",
       "75%        NaN          NaN     NaN   NaN    3.400000   400.000000   \n",
       "max        NaN          NaN     NaN   NaN   28.000000  1775.000000   \n",
       "\n",
       "           Albumin      Copper      Alk_Phos        SGOT  Tryglicerides  \\\n",
       "count   418.000000  310.000000    312.000000  312.000000     282.000000   \n",
       "unique         NaN         NaN           NaN         NaN            NaN   \n",
       "top            NaN         NaN           NaN         NaN            NaN   \n",
       "freq           NaN         NaN           NaN         NaN            NaN   \n",
       "mean      3.497440   97.648387   1982.655769  122.556346     124.702128   \n",
       "std       0.424972   85.613920   2140.388824   56.699525      65.148639   \n",
       "min       1.960000    4.000000    289.000000   26.350000      33.000000   \n",
       "25%       3.242500   41.250000    871.500000   80.600000      84.250000   \n",
       "50%       3.530000   73.000000   1259.000000  114.700000     108.000000   \n",
       "75%       3.770000  123.000000   1980.000000  151.900000     151.000000   \n",
       "max       4.640000  588.000000  13862.400000  457.250000     598.000000   \n",
       "\n",
       "         Platelets  Prothrombin       Stage  \n",
       "count   407.000000   416.000000  412.000000  \n",
       "unique         NaN          NaN         NaN  \n",
       "top            NaN          NaN         NaN  \n",
       "freq           NaN          NaN         NaN  \n",
       "mean    257.024570    10.731731    3.024272  \n",
       "std      98.325585     1.022000    0.882042  \n",
       "min      62.000000     9.000000    1.000000  \n",
       "25%     188.500000    10.000000    2.000000  \n",
       "50%     251.000000    10.600000    3.000000  \n",
       "75%     318.000000    11.100000    4.000000  \n",
       "max     721.000000    18.000000    4.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Your code\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'cirrhosis.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show first few rows\n",
    "display(df.head())\n",
    "\n",
    "# Show basic info\n",
    "print('Shape:', df.shape)\n",
    "df.info()\n",
    "\n",
    "# Show missing values per column\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Show summary statistics\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7189dad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after imputation:\n",
      "ID               0\n",
      "N_Days           0\n",
      "Status           0\n",
      "Drug             0\n",
      "Age              0\n",
      "Sex              0\n",
      "Ascites          0\n",
      "Hepatomegaly     0\n",
      "Spiders          0\n",
      "Edema            0\n",
      "Bilirubin        0\n",
      "Cholesterol      0\n",
      "Albumin          0\n",
      "Copper           0\n",
      "Alk_Phos         0\n",
      "SGOT             0\n",
      "Tryglicerides    0\n",
      "Platelets        0\n",
      "Prothrombin      0\n",
      "Stage            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "# For categorical columns, fill with mode\n",
    "categorical_cols = ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Status']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# For continuous columns, fill with median\n",
    "continuous_cols = ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin', 'Stage']\n",
    "for col in continuous_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Check again for missing values\n",
    "print('Missing values after imputation:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c67f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (334, 18)\n",
      "Test set shape: (84, 18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features and label\n",
    "y = df['Status']\n",
    "X = df.drop(['Status', 'ID'], axis=1)\n",
    "\n",
    "# Split into train and test sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print('Training set shape:', X_train.shape)\n",
    "print('Test set shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f703f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n",
      "Continuous features: ['N_Days', 'Age', 'Bilirubin', 'Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin', 'Stage']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N_Days</th>\n",
       "      <td>N_Days</td>\n",
       "      <td>int64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug</th>\n",
       "      <td>Drug</td>\n",
       "      <td>object</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>Age</td>\n",
       "      <td>int64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>Sex</td>\n",
       "      <td>object</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ascites</th>\n",
       "      <td>Ascites</td>\n",
       "      <td>object</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <td>Hepatomegaly</td>\n",
       "      <td>object</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiders</th>\n",
       "      <td>Spiders</td>\n",
       "      <td>object</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edema</th>\n",
       "      <td>Edema</td>\n",
       "      <td>object</td>\n",
       "      <td>Categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilirubin</th>\n",
       "      <td>Bilirubin</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cholesterol</th>\n",
       "      <td>Cholesterol</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albumin</th>\n",
       "      <td>Albumin</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Copper</th>\n",
       "      <td>Copper</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alk_Phos</th>\n",
       "      <td>Alk_Phos</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGOT</th>\n",
       "      <td>SGOT</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tryglicerides</th>\n",
       "      <td>Tryglicerides</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platelets</th>\n",
       "      <td>Platelets</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prothrombin</th>\n",
       "      <td>Prothrombin</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stage</th>\n",
       "      <td>Stage</td>\n",
       "      <td>float64</td>\n",
       "      <td>Continuous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature     Type     Category\n",
       "N_Days                N_Days    int64   Continuous\n",
       "Drug                    Drug   object  Categorical\n",
       "Age                      Age    int64   Continuous\n",
       "Sex                      Sex   object  Categorical\n",
       "Ascites              Ascites   object  Categorical\n",
       "Hepatomegaly    Hepatomegaly   object  Categorical\n",
       "Spiders              Spiders   object  Categorical\n",
       "Edema                  Edema   object  Categorical\n",
       "Bilirubin          Bilirubin  float64   Continuous\n",
       "Cholesterol      Cholesterol  float64   Continuous\n",
       "Albumin              Albumin  float64   Continuous\n",
       "Copper                Copper  float64   Continuous\n",
       "Alk_Phos            Alk_Phos  float64   Continuous\n",
       "SGOT                    SGOT  float64   Continuous\n",
       "Tryglicerides  Tryglicerides  float64   Continuous\n",
       "Platelets          Platelets  float64   Continuous\n",
       "Prothrombin      Prothrombin  float64   Continuous\n",
       "Stage                  Stage  float64   Continuous"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show feature types\n",
    "feature_types = pd.DataFrame({'Feature': X_train.columns,\n",
    "                              'Type': X_train.dtypes})\n",
    "\n",
    "# Identify categorical and continuous features\n",
    "categorical_features = feature_types[feature_types['Type'] == 'object']['Feature'].tolist()\n",
    "continuous_features = feature_types[feature_types['Type'] != 'object']['Feature'].tolist()\n",
    "\n",
    "print('Categorical features:', categorical_features)\n",
    "print('Continuous features:', continuous_features)\n",
    "\n",
    "feature_types['Category'] = feature_types['Feature'].apply(lambda x: 'Categorical' if x in categorical_features else 'Continuous')\n",
    "display(feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c462e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded training set shape: (334, 19)\n",
      "Encoded test set shape: (84, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_features]), columns=encoder.get_feature_names_out(categorical_features), index=X_train.index)\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test[categorical_features]), columns=encoder.get_feature_names_out(categorical_features), index=X_test.index)\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded columns\n",
    "X_train_final = pd.concat([X_train.drop(categorical_features, axis=1), X_train_encoded], axis=1)\n",
    "X_test_final = pd.concat([X_test.drop(categorical_features, axis=1), X_test_encoded], axis=1)\n",
    "\n",
    "print('Encoded training set shape:', X_train_final.shape)\n",
    "print('Encoded test set shape:', X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a204f7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution (counts):\n",
      "Status\n",
      "C     185\n",
      "D     129\n",
      "CL     20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution (percent):\n",
      "Status\n",
      "C     55.389222\n",
      "D     38.622754\n",
      "CL     5.988024\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set is imbalanced.\n"
     ]
    }
   ],
   "source": [
    "# Show label distribution in training data\n",
    "label_counts = y_train.value_counts()\n",
    "label_percent = y_train.value_counts(normalize=True) * 100\n",
    "print('Label distribution (counts):')\n",
    "print(label_counts)\n",
    "print('\\nLabel distribution (percent):')\n",
    "print(label_percent)\n",
    "\n",
    "# Visualize label distribution\n",
    "sns.countplot(x=y_train)\n",
    "plt.title('Label Distribution in Training Set')\n",
    "plt.xlabel('Survival State')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Is the training set balanced?\n",
    "if label_percent.min() < 20:\n",
    "    print('The training set is imbalanced.')\n",
    "else:\n",
    "    print('The training set is relatively balanced.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fce46a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression Test Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73        32\n",
      "           1       0.78      0.89      0.83        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.76        84\n",
      "   macro avg       0.52      0.53      0.52        84\n",
      "weighted avg       0.73      0.76      0.74        84\n",
      "\n",
      "Accuracy: 0.7619\n",
      "Weighted F1: 0.7447\n",
      "\n",
      "--- Random Forest Test Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73        32\n",
      "           1       0.75      0.87      0.80        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.75        84\n",
      "   macro avg       0.51      0.52      0.51        84\n",
      "weighted avg       0.72      0.75      0.73        84\n",
      "\n",
      "Accuracy: 0.7500\n",
      "Weighted F1: 0.7292\n",
      "\n",
      "--- XGBoost Test Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.59      0.66        32\n",
      "           1       0.74      0.83      0.78        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.69        84\n",
      "   macro avg       0.49      0.47      0.48        84\n",
      "weighted avg       0.69      0.69      0.69        84\n",
      "\n",
      "Accuracy: 0.6905\n",
      "Weighted F1: 0.6860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode target labels to numeric values for ML models\n",
    "label_map = {'D': 0, 'C': 1, 'CL': 2}\n",
    "y_train_encoded = y_train.map(label_map)\n",
    "y_test_encoded = y_test.map(label_map)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Validation method: Stratified 5-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Fit models and report test performance\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_final, y_train_encoded)\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    print(f'--- {name} Test Performance ---')\n",
    "    print(classification_report(y_test_encoded, y_pred))\n",
    "    print(f'Accuracy: {accuracy_score(y_test_encoded, y_pred):.4f}')\n",
    "    print(f'Weighted F1: {f1_score(y_test_encoded, y_pred, average=\"weighted\"):.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf90a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 (weighted) CV scores: [0.69956573 0.75458912 0.74688462 0.63424601 0.72353404]\n",
      "Logistic Regression Mean F1 (weighted): 0.7118\n",
      "\n",
      "Random Forest F1 (weighted) CV scores: [0.73670111 0.75249484 0.71936051 0.71664747 0.71877677]\n",
      "Random Forest Mean F1 (weighted): 0.7288\n",
      "\n",
      "Random Forest F1 (weighted) CV scores: [0.73670111 0.75249484 0.71936051 0.71664747 0.71877677]\n",
      "Random Forest Mean F1 (weighted): 0.7288\n",
      "\n",
      "XGBoost F1 (weighted) CV scores: [0.74626866 0.77013191 0.70858829 0.76458616 0.69218679]\n",
      "XGBoost Mean F1 (weighted): 0.7364\n",
      "\n",
      "XGBoost F1 (weighted) CV scores: [0.74626866 0.77013191 0.70858829 0.76458616 0.69218679]\n",
      "XGBoost Mean F1 (weighted): 0.7364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train_final, y_train_encoded, cv=cv, scoring='f1_weighted')\n",
    "    results[name] = scores\n",
    "    print(f'{name} F1 (weighted) CV scores:', scores)\n",
    "    print(f'{name} Mean F1 (weighted): {scores.mean():.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59c39f",
   "metadata": {},
   "source": [
    "Q2b. Justify design decisions\n",
    "\n",
    "Logistic Regression → baseline linear model, interpretable, quick to train.\n",
    "\n",
    "Random Forest → non-linear, handles categorical interactions, robust to noise.\n",
    "\n",
    "XGBoost → gradient boosting, strong learner, effective with imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14bb0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution after SMOTE: {0: 185, 1: 185, 2: 185}\n",
      "--- Logistic Regression Test Performance (Balanced) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65        32\n",
      "           1       0.82      0.66      0.73        47\n",
      "           2       0.06      0.20      0.10         5\n",
      "\n",
      "    accuracy                           0.62        84\n",
      "   macro avg       0.51      0.49      0.49        84\n",
      "weighted avg       0.71      0.62      0.66        84\n",
      "\n",
      "Accuracy: 0.6190\n",
      "Weighted F1: 0.6596\n",
      "\n",
      "--- Random Forest Test Performance (Balanced) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74        32\n",
      "           1       0.80      0.85      0.82        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.75        84\n",
      "   macro avg       0.52      0.52      0.52        84\n",
      "weighted avg       0.74      0.75      0.74        84\n",
      "\n",
      "Accuracy: 0.7500\n",
      "Weighted F1: 0.7441\n",
      "\n",
      "--- XGBoost Test Performance (Balanced) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69        32\n",
      "           1       0.76      0.81      0.78        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.69        84\n",
      "   macro avg       0.51      0.48      0.49        84\n",
      "weighted avg       0.72      0.69      0.70        84\n",
      "\n",
      "Accuracy: 0.6905\n",
      "Weighted F1: 0.7011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Handle label imbalance using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_final, y_train_encoded)\n",
    "\n",
    "print('Label distribution after SMOTE:', dict(zip(*np.unique(y_train_bal, return_counts=True))))\n",
    "\n",
    "# Train models on balanced data\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_bal, y_train_bal)\n",
    "    y_pred_bal = model.predict(X_test_final)\n",
    "    print(f'--- {name} Test Performance (Balanced) ---')\n",
    "    print(classification_report(y_test_encoded, y_pred_bal))\n",
    "    print(f'Accuracy: {accuracy_score(y_test_encoded, y_pred_bal):.4f}')\n",
    "    print(f'Weighted F1: {f1_score(y_test_encoded, y_pred_bal, average=\"weighted\"):.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d561f5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogisticRegression: CV (5-fold) & Test Metrics ===\n",
      "CV Accuracy:  0.7306 ± 0.0157\n",
      "CV F1 (w):    0.7098 ± 0.0178\n",
      "Test Accuracy:0.7619\n",
      "Test F1 (w):  0.7401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72        32\n",
      "           1       0.78      0.89      0.83        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.76        84\n",
      "   macro avg       0.51      0.53      0.52        84\n",
      "weighted avg       0.72      0.76      0.74        84\n",
      "\n",
      "\n",
      "=== RandomForest: CV (5-fold) & Test Metrics ===\n",
      "CV Accuracy:  0.7664 ± 0.0231\n",
      "CV F1 (w):    0.7407 ± 0.0235\n",
      "Test Accuracy:0.7857\n",
      "Test F1 (w):  0.7603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77        32\n",
      "           1       0.78      0.89      0.83        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.79        84\n",
      "   macro avg       0.53      0.55      0.54        84\n",
      "weighted avg       0.74      0.79      0.76        84\n",
      "\n",
      "\n",
      "=== XGBoost: CV (5-fold) & Test Metrics ===\n",
      "CV Accuracy:  0.7303 ± 0.0420\n",
      "CV F1 (w):    0.7205 ± 0.0412\n",
      "Test Accuracy:0.7024\n",
      "Test F1 (w):  0.6947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.68        32\n",
      "           1       0.74      0.83      0.78        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.70        84\n",
      "   macro avg       0.49      0.48      0.49        84\n",
      "weighted avg       0.69      0.70      0.69        84\n",
      "\n",
      "\n",
      "### Baseline Summary (sorted by Test F1 weighted)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_acc_mean</th>\n",
       "      <th>cv_acc_std</th>\n",
       "      <th>cv_f1_mean</th>\n",
       "      <th>cv_f1_std</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>test_precision_weighted</th>\n",
       "      <th>test_recall_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.766395</td>\n",
       "      <td>0.023098</td>\n",
       "      <td>0.740676</td>\n",
       "      <td>0.023468</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.760277</td>\n",
       "      <td>0.739947</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.730574</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>0.709837</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.740132</td>\n",
       "      <td>0.724184</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>0.041994</td>\n",
       "      <td>0.720495</td>\n",
       "      <td>0.041180</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.694701</td>\n",
       "      <td>0.693912</td>\n",
       "      <td>0.702381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  cv_acc_mean  cv_acc_std  cv_f1_mean  cv_f1_std  \\\n",
       "1        RandomForest     0.766395    0.023098    0.740676   0.023468   \n",
       "0  LogisticRegression     0.730574    0.015708    0.709837   0.017761   \n",
       "2             XGBoost     0.730303    0.041994    0.720495   0.041180   \n",
       "\n",
       "   test_accuracy  test_f1_weighted  test_precision_weighted  \\\n",
       "1       0.785714          0.760277                 0.739947   \n",
       "0       0.761905          0.740132                 0.724184   \n",
       "2       0.702381          0.694701                 0.693912   \n",
       "\n",
       "   test_recall_weighted  \n",
       "1              0.785714  \n",
       "0              0.761905  \n",
       "2              0.702381  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Over/Underfitting diagnostic:\n",
      "      RandomForest: CV F1=0.741 vs Test F1=0.760 | Gap=-0.020 -> Well-aligned\n",
      "LogisticRegression: CV F1=0.710 vs Test F1=0.740 | Gap=-0.030 -> Possible underfit\n",
      "           XGBoost: CV F1=0.720 vs Test F1=0.695 | Gap=+0.026 -> Well-aligned\n",
      "\n",
      "\n",
      "### Hyperparameter Tuning (GridSearchCV, scoring = F1_weighted)\n",
      "\n",
      "Best params for LogisticRegression: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "=== LogisticRegression_Tuned: CV (5-fold) & Test Metrics ===\n",
      "CV Accuracy:  0.7245 ± 0.0296\n",
      "CV F1 (w):    0.7054 ± 0.0283\n",
      "Test Accuracy:0.7619\n",
      "Test F1 (w):  0.7401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72        32\n",
      "           1       0.78      0.89      0.83        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.76        84\n",
      "   macro avg       0.51      0.53      0.52        84\n",
      "weighted avg       0.72      0.76      0.74        84\n",
      "\n",
      "\n",
      "Best params for RandomForest: {'max_depth': 8, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 400}\n",
      "\n",
      "=== RandomForest_Tuned: CV (5-fold) & Test Metrics ===\n",
      "CV Accuracy:  0.7635 ± 0.0212\n",
      "CV F1 (w):    0.7514 ± 0.0227\n",
      "Test Accuracy:0.7381\n",
      "Test F1 (w):  0.7180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71        32\n",
      "           1       0.75      0.85      0.80        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.74        84\n",
      "   macro avg       0.50      0.51      0.50        84\n",
      "weighted avg       0.70      0.74      0.72        84\n",
      "\n",
      "\n",
      "Best params for XGBoost: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500, 'subsample': 0.8}\n",
      "\n",
      "=== XGBoost_Tuned: CV (5-fold) & Test Metrics ===\n",
      "CV Accuracy:  0.7603 ± 0.0403\n",
      "CV F1 (w):    0.7538 ± 0.0409\n",
      "Test Accuracy:0.7143\n",
      "Test F1 (w):  0.7031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70        32\n",
      "           1       0.74      0.83      0.78        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.71        84\n",
      "   macro avg       0.50      0.50      0.49        84\n",
      "weighted avg       0.70      0.71      0.70        84\n",
      "\n",
      "\n",
      "### Tuned Models Summary (sorted by Test F1 weighted)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_acc_mean</th>\n",
       "      <th>cv_acc_std</th>\n",
       "      <th>cv_f1_mean</th>\n",
       "      <th>cv_f1_std</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>test_precision_weighted</th>\n",
       "      <th>test_recall_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Tuned</td>\n",
       "      <td>0.724514</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.705397</td>\n",
       "      <td>0.028312</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.740132</td>\n",
       "      <td>0.724184</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest_Tuned</td>\n",
       "      <td>0.763546</td>\n",
       "      <td>0.021184</td>\n",
       "      <td>0.751352</td>\n",
       "      <td>0.022651</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.717972</td>\n",
       "      <td>0.701647</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_Tuned</td>\n",
       "      <td>0.760289</td>\n",
       "      <td>0.040325</td>\n",
       "      <td>0.753752</td>\n",
       "      <td>0.040873</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.703095</td>\n",
       "      <td>0.697439</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  cv_acc_mean  cv_acc_std  cv_f1_mean  cv_f1_std  \\\n",
       "0  LogisticRegression_Tuned     0.724514    0.029560    0.705397   0.028312   \n",
       "1        RandomForest_Tuned     0.763546    0.021184    0.751352   0.022651   \n",
       "2             XGBoost_Tuned     0.760289    0.040325    0.753752   0.040873   \n",
       "\n",
       "   test_accuracy  test_f1_weighted  test_precision_weighted  \\\n",
       "0       0.761905          0.740132                 0.724184   \n",
       "1       0.738095          0.717972                 0.701647   \n",
       "2       0.714286          0.703095                 0.697439   \n",
       "\n",
       "   test_recall_weighted  \n",
       "0              0.761905  \n",
       "1              0.738095  \n",
       "2              0.714286  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE class distribution: {0: 185, 1: 185, 2: 185}\n",
      "\n",
      "=== LogisticRegression_Tuned_SMOTE: CV (5-fold) & Test Metrics ===\n",
      "CV Accuracy:  0.6919 ± 0.0281\n",
      "CV F1 (w):    0.6897 ± 0.0292\n",
      "Test Accuracy:0.6429\n",
      "Test F1 (w):  0.6757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66        32\n",
      "           1       0.80      0.70      0.75        47\n",
      "           2       0.07      0.20      0.11         5\n",
      "\n",
      "    accuracy                           0.64        84\n",
      "   macro avg       0.52      0.51      0.50        84\n",
      "weighted avg       0.72      0.64      0.68        84\n",
      "\n",
      "\n",
      "=== RandomForest_Tuned_SMOTE: CV (5-fold) & Test Metrics ===\n",
      "CV Accuracy:  0.8216 ± 0.0270\n",
      "CV F1 (w):    0.8189 ± 0.0269\n",
      "Test Accuracy:0.6786\n",
      "Test F1 (w):  0.7014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.59      0.67        32\n",
      "           1       0.79      0.79      0.79        47\n",
      "           2       0.08      0.20      0.12         5\n",
      "\n",
      "    accuracy                           0.68        84\n",
      "   macro avg       0.54      0.53      0.52        84\n",
      "weighted avg       0.73      0.68      0.70        84\n",
      "\n",
      "\n",
      "=== XGBoost_Tuned_SMOTE: CV (5-fold) & Test Metrics ===\n",
      "CV Accuracy:  0.8541 ± 0.0264\n",
      "CV F1 (w):    0.8530 ± 0.0260\n",
      "Test Accuracy:0.6548\n",
      "Test F1 (w):  0.6694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64        32\n",
      "           1       0.75      0.77      0.76        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.65        84\n",
      "   macro avg       0.48      0.45      0.47        84\n",
      "weighted avg       0.69      0.65      0.67        84\n",
      "\n",
      "\n",
      "### Tuned + SMOTE Summary (sorted by Test F1 weighted)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_acc_mean</th>\n",
       "      <th>cv_acc_std</th>\n",
       "      <th>cv_f1_mean</th>\n",
       "      <th>cv_f1_std</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>test_precision_weighted</th>\n",
       "      <th>test_recall_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest_Tuned_SMOTE</td>\n",
       "      <td>0.821622</td>\n",
       "      <td>0.026967</td>\n",
       "      <td>0.818946</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.701447</td>\n",
       "      <td>0.734960</td>\n",
       "      <td>0.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Tuned_SMOTE</td>\n",
       "      <td>0.691892</td>\n",
       "      <td>0.028145</td>\n",
       "      <td>0.689733</td>\n",
       "      <td>0.029153</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.675713</td>\n",
       "      <td>0.717326</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_Tuned_SMOTE</td>\n",
       "      <td>0.854054</td>\n",
       "      <td>0.026358</td>\n",
       "      <td>0.853005</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.669419</td>\n",
       "      <td>0.687720</td>\n",
       "      <td>0.654762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  cv_acc_mean  cv_acc_std  cv_f1_mean  \\\n",
       "1        RandomForest_Tuned_SMOTE     0.821622    0.026967    0.818946   \n",
       "0  LogisticRegression_Tuned_SMOTE     0.691892    0.028145    0.689733   \n",
       "2             XGBoost_Tuned_SMOTE     0.854054    0.026358    0.853005   \n",
       "\n",
       "   cv_f1_std  test_accuracy  test_f1_weighted  test_precision_weighted  \\\n",
       "1   0.026914       0.678571          0.701447                 0.734960   \n",
       "0   0.029153       0.642857          0.675713                 0.717326   \n",
       "2   0.025958       0.654762          0.669419                 0.687720   \n",
       "\n",
       "   test_recall_weighted  \n",
       "1              0.678571  \n",
       "0              0.642857  \n",
       "2              0.654762  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Recommendations\n",
      "\n",
      "Best (Baseline): RandomForest | Test F1 (w)=0.7603, Test Acc=0.7857 | CV F1=0.7407\n",
      "\n",
      "Best (Tuned (no SMOTE)): LogisticRegression_Tuned | Test F1 (w)=0.7401, Test Acc=0.7619 | CV F1=0.7054\n",
      "\n",
      "Best (Tuned + SMOTE): RandomForest_Tuned_SMOTE | Test F1 (w)=0.7014, Test Acc=0.6786 | CV F1=0.8189\n",
      "\n",
      ">>> FINAL RECOMMENDATION:\n",
      "Use **RandomForest** (Baseline) with Test F1 (weighted) = 0.7603 and Accuracy = 0.7857.\n",
      "Rationale: chosen by highest weighted-F1 on the held-out test set; weighted-F1 prioritises performance across all classes in the imbalanced setting.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Q2a–Q2e: FULL CONTINUATION\n",
    "# =========================\n",
    "# Assumes you have already run the previous cells that:\n",
    "# - load/clean/impute `df`\n",
    "# - split into X_train, X_test, y_train, y_test\n",
    "# - one-hot encode categoricals into X_train_final / X_test_final\n",
    "# - encoded labels into y_train_encoded / y_test_encoded\n",
    "# - defined `cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)`\n",
    "# - installed xgboost (for XGBClassifier)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# Helper: evaluate a model\n",
    "# -------------------------\n",
    "def evaluate_model(name, model, X_tr, y_tr, X_te, y_te, cv, verbose=True):\n",
    "    \"\"\"Return CV and Test metrics for a classifier.\"\"\"\n",
    "    cv_f1 = cross_val_score(model, X_tr, y_tr, cv=cv, scoring=\"f1_weighted\")\n",
    "    cv_acc = cross_val_score(model, X_tr, y_tr, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    test_metrics = {\n",
    "        \"accuracy\": accuracy_score(y_te, y_pred),\n",
    "        \"f1_weighted\": f1_score(y_te, y_pred, average=\"weighted\"),\n",
    "        \"precision_weighted\": precision_score(y_te, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"recall_weighted\": recall_score(y_te, y_pred, average=\"weighted\")\n",
    "    }\n",
    "    if verbose:\n",
    "        print(f\"\\n=== {name}: CV (5-fold) & Test Metrics ===\")\n",
    "        print(f\"CV Accuracy:  {cv_acc.mean():.4f} ± {cv_acc.std():.4f}\")\n",
    "        print(f\"CV F1 (w):    {cv_f1.mean():.4f} ± {cv_f1.std():.4f}\")\n",
    "        print(f\"Test Accuracy:{test_metrics['accuracy']:.4f}\")\n",
    "        print(f\"Test F1 (w):  {test_metrics['f1_weighted']:.4f}\")\n",
    "        print(classification_report(y_te, y_pred))\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"cv_acc_mean\": cv_acc.mean(), \"cv_acc_std\": cv_acc.std(),\n",
    "        \"cv_f1_mean\": cv_f1.mean(),   \"cv_f1_std\": cv_f1.std(),\n",
    "        **{f\"test_{k}\": v for k, v in test_metrics.items()}\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Q2a: Validation & Performance (baseline)\n",
    "# -------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "baseline_models = OrderedDict({\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000, random_state=42, multi_class=\"auto\", solver=\"lbfgs\"),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        random_state=42, n_estimators=300, learning_rate=0.1, max_depth=4,\n",
    "        subsample=0.9, colsample_bytree=0.9, objective=\"multi:softprob\", eval_metric=\"mlogloss\"\n",
    "    )\n",
    "})\n",
    "\n",
    "baseline_rows = []\n",
    "for name, clf in baseline_models.items():\n",
    "    row = evaluate_model(name, clf, X_train_final, y_train_encoded, X_test_final, y_test_encoded, cv)\n",
    "    baseline_rows.append(row)\n",
    "\n",
    "baseline_summary = pd.DataFrame(baseline_rows).sort_values(\"test_f1_weighted\", ascending=False)\n",
    "print(\"\\n### Baseline Summary (sorted by Test F1 weighted)\")\n",
    "display(baseline_summary)\n",
    "\n",
    "print(\"\\nOver/Underfitting diagnostic:\")\n",
    "for _, r in baseline_summary.iterrows():\n",
    "    gap = r[\"cv_f1_mean\"] - r[\"test_f1_weighted\"]\n",
    "    status = \"Possible overfit\" if gap > 0.03 else (\"Possible underfit\" if gap < -0.03 else \"Well-aligned\")\n",
    "    print(f\"{r['model']:>18s}: CV F1={r['cv_f1_mean']:.3f} vs Test F1={r['test_f1_weighted']:.3f} | Gap={gap:+.3f} -> {status}\")\n",
    "\n",
    "# ------------------------------------\n",
    "# Q2b: (in-code notes / design choices)\n",
    "# ------------------------------------\n",
    "# Logistic Regression: linear decision boundaries; strong baseline; interpretable; fast.\n",
    "# Random Forest: non-linear, bagging reduces variance; handles interactions; robust to outliers.\n",
    "# XGBoost: gradient-boosted trees; powerful on tabular data; handles complex non-linearities;\n",
    "#          built-in regularization to control overfitting.\n",
    "\n",
    "# ------------------------------------\n",
    "# Q2c: Hyperparameter Tuning (GridSearchCV)\n",
    "# ------------------------------------\n",
    "print(\"\\n\\n### Hyperparameter Tuning (GridSearchCV, scoring = F1_weighted)\")\n",
    "grids = {}\n",
    "\n",
    "# Logistic Regression grid\n",
    "lr = LogisticRegression(max_iter=4000, random_state=42, multi_class=\"auto\")\n",
    "lr_param_grid = [\n",
    "    {\"solver\": [\"lbfgs\"], \"C\": [0.01, 0.1, 1.0, 10.0], \"penalty\": [\"l2\"]},\n",
    "    {\"solver\": [\"saga\"],  \"C\": [0.01, 0.1, 1.0, 10.0], \"penalty\": [\"l1\", \"l2\"]}\n",
    "]\n",
    "grids[\"LogisticRegression\"] = GridSearchCV(lr, lr_param_grid, cv=cv, n_jobs=-1, scoring=\"f1_weighted\", refit=True)\n",
    "\n",
    "# Random Forest grid\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [None, 8, 12],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "grids[\"RandomForest\"] = GridSearchCV(rf, rf_param_grid, cv=cv, n_jobs=-1, scoring=\"f1_weighted\", refit=True)\n",
    "\n",
    "# XGBoost grid\n",
    "xgb = XGBClassifier(random_state=42, objective=\"multi:softprob\", eval_metric=\"mlogloss\", tree_method=\"hist\")\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [300, 500],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "grids[\"XGBoost\"] = GridSearchCV(xgb, xgb_param_grid, cv=cv, n_jobs=-1, scoring=\"f1_weighted\", refit=True)\n",
    "\n",
    "tuned_rows = []\n",
    "best_estimators = {}\n",
    "\n",
    "for name, grid in grids.items():\n",
    "    grid.fit(X_train_final, y_train_encoded)\n",
    "    best_estimators[name] = grid.best_estimator_\n",
    "    print(f\"\\nBest params for {name}: {grid.best_params_}\")\n",
    "    tuned_rows.append(\n",
    "        evaluate_model(f\"{name}_Tuned\", grid.best_estimator_, X_train_final, y_train_encoded, X_test_final, y_test_encoded, cv)\n",
    "    )\n",
    "\n",
    "tuned_summary = pd.DataFrame(tuned_rows).sort_values(\"test_f1_weighted\", ascending=False)\n",
    "print(\"\\n### Tuned Models Summary (sorted by Test F1 weighted)\")\n",
    "display(tuned_summary)\n",
    "\n",
    "# ------------------------------------\n",
    "# Q2d: Handle Imbalance (SMOTE) + Re-evaluate tuned models\n",
    "# ------------------------------------\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_final, y_train_encoded)\n",
    "print(\"After SMOTE class distribution:\", dict(zip(*np.unique(y_train_bal, return_counts=True))))\n",
    "\n",
    "smote_rows = []\n",
    "for name, best_est in best_estimators.items():\n",
    "    smote_rows.append(\n",
    "        evaluate_model(f\"{name}_Tuned_SMOTE\", best_est, X_train_bal, y_train_bal, X_test_final, y_test_encoded, cv)\n",
    "    )\n",
    "smote_summary = pd.DataFrame(smote_rows).sort_values(\"test_f1_weighted\", ascending=False)\n",
    "print(\"\\n### Tuned + SMOTE Summary (sorted by Test F1 weighted)\")\n",
    "display(smote_summary)\n",
    "\n",
    "# ------------------------------------\n",
    "# Q2e: Recommendation based on results\n",
    "# ------------------------------------\n",
    "def pick_best(df_summary, tag):\n",
    "    row = df_summary.iloc[0]\n",
    "    print(f\"\\nBest ({tag}): {row['model']} | Test F1 (w)={row['test_f1_weighted']:.4f}, \"\n",
    "          f\"Test Acc={row['test_accuracy']:.4f} | CV F1={row['cv_f1_mean']:.4f}\")\n",
    "\n",
    "print(\"\\n### Recommendations\")\n",
    "pick_best(baseline_summary, \"Baseline\")\n",
    "pick_best(tuned_summary, \"Tuned (no SMOTE)\")\n",
    "pick_best(smote_summary, \"Tuned + SMOTE\")\n",
    "\n",
    "# Final overall pick (highest Test F1 across all scenarios)\n",
    "all_compare = pd.concat([\n",
    "    baseline_summary.assign(stage=\"Baseline\"),\n",
    "    tuned_summary.assign(stage=\"Tuned\"),\n",
    "    smote_summary.assign(stage=\"Tuned+SMOTE\")\n",
    "], ignore_index=True).sort_values(\"test_f1_weighted\", ascending=False)\n",
    "\n",
    "best_overall = all_compare.iloc[0]\n",
    "print(\"\\n>>> FINAL RECOMMENDATION:\")\n",
    "print(f\"Use **{best_overall['model']}** ({best_overall['stage']}) \"\n",
    "      f\"with Test F1 (weighted) = {best_overall['test_f1_weighted']:.4f} and \"\n",
    "      f\"Accuracy = {best_overall['test_accuracy']:.4f}.\")\n",
    "print(\"Rationale: chosen by highest weighted-F1 on the held-out test set; \"\n",
    "      \"weighted-F1 prioritises performance across all classes in the imbalanced setting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16dca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Best Model on Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64        32\n",
      "           1       0.75      0.77      0.76        47\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.65        84\n",
      "   macro avg       0.48      0.45      0.47        84\n",
      "weighted avg       0.69      0.65      0.67        84\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  9  4]\n",
      " [ 6 36  5]\n",
      " [ 2  3  0]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 18 is out of bounds for axis 0 with size 18",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Importances (Tree-based)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(\u001b[38;5;28mrange\u001b[39m(X_train_final\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), importances[indices], align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(\u001b[38;5;28mrange\u001b[39m(X_train_final\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), X\u001b[38;5;241m.\u001b[39mcolumns[indices], rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n\u001b[0;32m     30\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     31\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5428\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5419\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   5420\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   5421\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a boolean indexer with length 0 on an Index with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5422\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength greater than 0 is deprecated and will raise in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5425\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   5426\u001b[0m             )\n\u001b[1;32m-> 5428\u001b[0m result \u001b[38;5;241m=\u001b[39m getitem(key)\n\u001b[0;32m   5429\u001b[0m \u001b[38;5;66;03m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[0;32m   5430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 18 is out of bounds for axis 0 with size 18"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Q3 – Prediction on Test Set\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Best model from Q2 (update if yours differs)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "\n",
    "# Performance metrics\n",
    "print(\"Classification Report (Best Model on Test Set):\")\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_encoded, y_pred))\n",
    "\n",
    "# Q4 – Feature Importance Analysis\n",
    "\n",
    "# (A) Tree-based feature importance\n",
    "importances = best_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Feature Importances (Tree-based)\")\n",
    "plt.bar(range(X_train_final.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train_final.shape[1]), X.columns[indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (B) Permutation importance\n",
    "perm_importance = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "sorted_idx = perm_importance.importances_mean.argsort()[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.boxplot(perm_importance.importances[sorted_idx].T,\n",
    "            vert=False, labels=X.columns[sorted_idx])\n",
    "plt.title(\"Permutation Importance (Test Set)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical reasoning\n",
    "print(\"\\nPermutation Importance (mean decrease in score):\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{X.columns[i]}: {perm_importance.importances_mean[i]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
