{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3c9a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 as cv \n",
    "from sklearn.cluster import KMeans \n",
    "import pickle \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn import svm \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "class Dictionary(object): \n",
    "    def __init__(self, name, img_filenames, num_words): \n",
    "        self.name = name #name of your dictionary \n",
    "        self.img_filenames = img_filenames #list of image filenames \n",
    "        self.num_words = num_words #the number of words \n",
    "         \n",
    "        self.training_data = [] #training data used to learn clusters \n",
    "        self.words = [] #list of words, which are the centroids of clusters \n",
    "     \n",
    "    def learn(self): \n",
    "        sift = cv.SIFT_create() \n",
    "         \n",
    "        num_keypoints = [] #used to store the number of keypoints in each image \n",
    "         \n",
    "        #load training images and compute SIFT descriptors \n",
    "        for filename in self.img_filenames: \n",
    "            img = cv.imread(filename) \n",
    "            img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) \n",
    "            list_des = sift.detectAndCompute(img_gray, None)[1] \n",
    "            if list_des is None: \n",
    "                num_keypoints.append(0) \n",
    "            else: \n",
    "                num_keypoints.append(len(list_des)) \n",
    "                for des in list_des: \n",
    "                    self.training_data.append(des) \n",
    "             \n",
    "        #cluster SIFT descriptors using K-means algorithm \n",
    "        kmeans = KMeans(self.num_words) \n",
    "        kmeans.fit(self.training_data) \n",
    "        self.words = kmeans.cluster_centers_ \n",
    "         \n",
    "        #create word histograms for training images \n",
    "        training_word_histograms = [] #list of word histograms of all training images \n",
    "        index = 0 \n",
    "        for i in range(0, len(self.img_filenames)): #for each file, create a histogram \n",
    "            histogram = np.zeros(self.num_words, np.float32) \n",
    "            #if some keypoints exist \n",
    "            if num_keypoints[i] > 0: \n",
    "                for j in range(0, num_keypoints[i]): \n",
    "                    histogram[kmeans.labels_[j + index]] += 1 \n",
    "                index += num_keypoints[i] \n",
    "                histogram /= num_keypoints[i] \n",
    "                training_word_histograms.append(histogram) \n",
    "         \n",
    "        return training_word_histograms\n",
    "    \n",
    "    def create_word_histograms(self, img_filenames): \n",
    "        sift = cv.SIFT_create() \n",
    "        histograms = [] \n",
    "         \n",
    "        for filename in img_filenames: \n",
    "            img = cv.imread(filename) \n",
    "            img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) \n",
    "            descriptors = sift.detectAndCompute(img_gray, None)[1] \n",
    "         \n",
    "            histogram = np.zeros(self.num_words, np.float32) #word histogram  \n",
    "         \n",
    "            if descriptors is not None: \n",
    "                for des in descriptors: \n",
    "                    #find the best matching word \n",
    "                    min_distance = 1111111 #this can be any large number \n",
    "                    matching_word_ID = -1 #initialise ID with an impractical value \n",
    "                     \n",
    "                    for i in range(0, self.num_words): #find the best matching word \n",
    "                        distance = np.linalg.norm(des - self.words[i]) \n",
    "                        if distance < min_distance: \n",
    "                            min_distance = distance \n",
    "                            matching_word_ID = i \n",
    "                     \n",
    "                    histogram[matching_word_ID] += 1 \n",
    "                 \n",
    "                histogram /= len(descriptors) #make histogram a prob distribution \n",
    "         \n",
    "            histograms.append(histogram) \n",
    "         \n",
    "        return histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "622c304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FoodImages/Train/Cakes/cake1.png', 'FoodImages/Train/Cakes/cake10.jpg', 'FoodImages/Train/Cakes/cake11.jpg', 'FoodImages/Train/Cakes/cake12.jpg', 'FoodImages/Train/Cakes/cake13.jpg', 'FoodImages/Train/Cakes/cake14.jpg', 'FoodImages/Train/Cakes/cake15.jpg', 'FoodImages/Train/Cakes/cake16.jpg', 'FoodImages/Train/Cakes/cake17.jpg', 'FoodImages/Train/Cakes/cake18.jpg', 'FoodImages/Train/Cakes/cake19.jpg', 'FoodImages/Train/Cakes/cake2.png', 'FoodImages/Train/Cakes/cake20.jpg', 'FoodImages/Train/Cakes/cake21.jpg', 'FoodImages/Train/Cakes/cake22.jpg', 'FoodImages/Train/Cakes/cake23.jpg', 'FoodImages/Train/Cakes/cake24.jpg', 'FoodImages/Train/Cakes/cake25.jpg', 'FoodImages/Train/Cakes/cake26.jpg', 'FoodImages/Train/Cakes/cake27.jpg', 'FoodImages/Train/Cakes/cake28.jpg', 'FoodImages/Train/Cakes/cake29.jpg', 'FoodImages/Train/Cakes/cake3.png', 'FoodImages/Train/Cakes/cake30.jpg', 'FoodImages/Train/Cakes/cake4.jpg', 'FoodImages/Train/Cakes/cake5.jpg', 'FoodImages/Train/Cakes/cake6.jpg', 'FoodImages/Train/Cakes/cake7.jpg', 'FoodImages/Train/Cakes/cake8.jpg', 'FoodImages/Train/Cakes/cake9.jpg', 'FoodImages/Train/Pasta/pasta1.jpg', 'FoodImages/Train/Pasta/pasta10.jpg', 'FoodImages/Train/Pasta/pasta11.jpg', 'FoodImages/Train/Pasta/pasta12.jpg', 'FoodImages/Train/Pasta/pasta13.jpg', 'FoodImages/Train/Pasta/pasta14.jpg', 'FoodImages/Train/Pasta/pasta15.jpg', 'FoodImages/Train/Pasta/pasta16.jpg', 'FoodImages/Train/Pasta/pasta17.jpg', 'FoodImages/Train/Pasta/pasta18.jpg', 'FoodImages/Train/Pasta/pasta19.jpg', 'FoodImages/Train/Pasta/pasta2.jpg', 'FoodImages/Train/Pasta/pasta20.jpg', 'FoodImages/Train/Pasta/pasta21.png', 'FoodImages/Train/Pasta/pasta22.png', 'FoodImages/Train/Pasta/pasta23.png', 'FoodImages/Train/Pasta/pasta24.png', 'FoodImages/Train/Pasta/pasta25.png', 'FoodImages/Train/Pasta/pasta26.png', 'FoodImages/Train/Pasta/pasta27.png', 'FoodImages/Train/Pasta/pasta28.png', 'FoodImages/Train/Pasta/pasta29.jpg', 'FoodImages/Train/Pasta/pasta3.jpg', 'FoodImages/Train/Pasta/pasta30.jpg', 'FoodImages/Train/Pasta/pasta4.jpg', 'FoodImages/Train/Pasta/pasta5.jpg', 'FoodImages/Train/Pasta/pasta6.jpg', 'FoodImages/Train/Pasta/pasta7.jpg', 'FoodImages/Train/Pasta/pasta8.jpg', 'FoodImages/Train/Pasta/pasta9.jpg', 'FoodImages/Train/Pizza/pizza1.png', 'FoodImages/Train/Pizza/pizza10.jpg', 'FoodImages/Train/Pizza/pizza11.jpg', 'FoodImages/Train/Pizza/pizza12.jpg', 'FoodImages/Train/Pizza/pizza13.jpg', 'FoodImages/Train/Pizza/pizza14.jpg', 'FoodImages/Train/Pizza/pizza15.jpg', 'FoodImages/Train/Pizza/pizza16.jpg', 'FoodImages/Train/Pizza/pizza17.jpg', 'FoodImages/Train/Pizza/pizza18.jpg', 'FoodImages/Train/Pizza/pizza19.jpg', 'FoodImages/Train/Pizza/pizza2.jpg', 'FoodImages/Train/Pizza/pizza20.jpg', 'FoodImages/Train/Pizza/pizza21.jpg', 'FoodImages/Train/Pizza/pizza22.jpg', 'FoodImages/Train/Pizza/pizza23.jpg', 'FoodImages/Train/Pizza/pizza24.jpg', 'FoodImages/Train/Pizza/pizza25.jpg', 'FoodImages/Train/Pizza/pizza26.jpg', 'FoodImages/Train/Pizza/pizza27.jpg', 'FoodImages/Train/Pizza/pizza28.jpg', 'FoodImages/Train/Pizza/pizza29.jpg', 'FoodImages/Train/Pizza/pizza3.jpg', 'FoodImages/Train/Pizza/pizza30.jpg', 'FoodImages/Train/Pizza/pizza4.jpg', 'FoodImages/Train/Pizza/pizza5.jpg', 'FoodImages/Train/Pizza/pizza6.jpg', 'FoodImages/Train/Pizza/pizza7.jpg', 'FoodImages/Train/Pizza/pizza8.jpg', 'FoodImages/Train/Pizza/pizza9.jpg']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    " \n",
    "foods = ['Cakes', 'Pasta', 'Pizza'] \n",
    "path = 'FoodImages/' \n",
    "training_file_names = [] \n",
    "training_food_labels = [] \n",
    "for i in range(0, len(foods)): \n",
    "    sub_path = path + 'Train/' + foods[i] + '/' \n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)] \n",
    "    sub_food_labels = [i] * len(sub_file_names) #create a list of N elements, all are i \n",
    "    training_file_names += sub_file_names \n",
    "    training_food_labels += sub_food_labels \n",
    "     \n",
    "print(training_file_names) \n",
    "print(training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8534ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 50 \n",
    "dictionary_name = 'food' \n",
    "dictionary = Dictionary(dictionary_name, training_file_names, num_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b562af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_word_histograms = dictionary.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f910b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dictionary \n",
    "with open('food_dictionary.dic', 'wb') as f: #'wb' is for binary write \n",
    "    pickle.dump(dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a098f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('food_dictionary.dic', 'rb') as f: #'rb' is for binary read \n",
    "    dictionary = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12cb00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_names = [] \n",
    "test_food_labels = []\n",
    "\n",
    "#load test images and create word histograms\n",
    "for i in range(0, len(foods)): \n",
    "    sub_path = path + 'Test/' + foods[i] + '/' \n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)] \n",
    "    sub_food_labels = [i] * len(sub_file_names) #create a list of N elements, all are i \n",
    "    test_file_names += sub_file_names \n",
    "    test_food_labels += sub_food_labels \n",
    "    \n",
    "word_histograms = dictionary.create_word_histograms(test_file_names) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4cc6b",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "369c8e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nearest_neighbour: 5\n",
      "[[18  5  7]\n",
      " [ 0 26  4]\n",
      " [ 1  8 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.60      0.73        30\n",
      "           1       0.67      0.87      0.75        30\n",
      "           2       0.66      0.70      0.68        30\n",
      "\n",
      "    accuracy                           0.72        90\n",
      "   macro avg       0.76      0.72      0.72        90\n",
      "weighted avg       0.76      0.72      0.72        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 5 #number of neighbours \n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours) \n",
    "knn.fit(training_word_histograms, training_food_labels) \n",
    "predicted_food_labels = knn.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"num_nearest_neighbour:\", num_nearest_neighbours)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cf3a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nearest_neighbour: 10\n",
      "[[18  5  7]\n",
      " [ 0 26  4]\n",
      " [ 0  8 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75        30\n",
      "           1       0.67      0.87      0.75        30\n",
      "           2       0.67      0.73      0.70        30\n",
      "\n",
      "    accuracy                           0.73        90\n",
      "   macro avg       0.78      0.73      0.73        90\n",
      "weighted avg       0.78      0.73      0.73        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 10 #number of neighbours \n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours) \n",
    "knn.fit(training_word_histograms, training_food_labels) \n",
    "predicted_food_labels = knn.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"num_nearest_neighbour:\", num_nearest_neighbours)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45083710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nearest_neighbour: 15\n",
      "[[16  6  8]\n",
      " [ 0 25  5]\n",
      " [ 0  9 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.70        30\n",
      "           1       0.62      0.83      0.71        30\n",
      "           2       0.62      0.70      0.66        30\n",
      "\n",
      "    accuracy                           0.69        90\n",
      "   macro avg       0.75      0.69      0.69        90\n",
      "weighted avg       0.75      0.69      0.69        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 15 #number of neighbours \n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours) \n",
    "knn.fit(training_word_histograms, training_food_labels) \n",
    "predicted_food_labels = knn.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"num_nearest_neighbour:\", num_nearest_neighbours)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efd5df16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nearest_neighbour: 20\n",
      "[[13 10  7]\n",
      " [ 0 26  4]\n",
      " [ 0 10 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60        30\n",
      "           1       0.57      0.87      0.68        30\n",
      "           2       0.65      0.67      0.66        30\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.74      0.66      0.65        90\n",
      "weighted avg       0.74      0.66      0.65        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 20 #number of neighbours \n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours) \n",
    "knn.fit(training_word_histograms, training_food_labels) \n",
    "predicted_food_labels = knn.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"num_nearest_neighbour:\", num_nearest_neighbours)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5caa209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nearest_neighbour: 25\n",
      "[[11 13  6]\n",
      " [ 0 26  4]\n",
      " [ 0  9 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54        30\n",
      "           1       0.54      0.87      0.67        30\n",
      "           2       0.68      0.70      0.69        30\n",
      "\n",
      "    accuracy                           0.64        90\n",
      "   macro avg       0.74      0.64      0.63        90\n",
      "weighted avg       0.74      0.64      0.63        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 25 #number of neighbours \n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours) \n",
    "knn.fit(training_word_histograms, training_food_labels) \n",
    "predicted_food_labels = knn.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"num_nearest_neighbour:\", num_nearest_neighbours)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db37c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nearest_neighbour: 30\n",
      "[[ 8 14  8]\n",
      " [ 0 25  5]\n",
      " [ 0  6 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.42        30\n",
      "           1       0.56      0.83      0.67        30\n",
      "           2       0.65      0.80      0.72        30\n",
      "\n",
      "    accuracy                           0.63        90\n",
      "   macro avg       0.73      0.63      0.60        90\n",
      "weighted avg       0.73      0.63      0.60        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_nearest_neighbours = 30 #number of neighbours \n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours) \n",
    "knn.fit(training_word_histograms, training_food_labels) \n",
    "predicted_food_labels = knn.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"num_nearest_neighbour:\", num_nearest_neighbours)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d4264",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07db0a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10\n",
      "[[25  2  3]\n",
      " [ 0 23  7]\n",
      " [ 1  1 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89        30\n",
      "           1       0.88      0.77      0.82        30\n",
      "           2       0.74      0.93      0.82        30\n",
      "\n",
      "    accuracy                           0.84        90\n",
      "   macro avg       0.86      0.84      0.85        90\n",
      "weighted avg       0.86      0.84      0.85        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = 10\n",
    "svm_classifier = svm.SVC(C = C, #see slide 32 in week 4 handouts \n",
    "kernel = 'linear') #see slide 35 in week 4 handouts \n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = svm_classifier.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"C:\", C)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a161b498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 20\n",
      "[[26  2  2]\n",
      " [ 0 23  7]\n",
      " [ 1  1 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        30\n",
      "           1       0.88      0.77      0.82        30\n",
      "           2       0.76      0.93      0.84        30\n",
      "\n",
      "    accuracy                           0.86        90\n",
      "   macro avg       0.87      0.86      0.86        90\n",
      "weighted avg       0.87      0.86      0.86        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = 20\n",
    "svm_classifier = svm.SVC(C = C, #see slide 32 in week 4 handouts \n",
    "kernel = 'linear') #see slide 35 in week 4 handouts \n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = svm_classifier.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"C:\", C)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce9debb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 30\n",
      "[[26  2  2]\n",
      " [ 0 22  8]\n",
      " [ 1  1 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91        30\n",
      "           1       0.88      0.73      0.80        30\n",
      "           2       0.74      0.93      0.82        30\n",
      "\n",
      "    accuracy                           0.84        90\n",
      "   macro avg       0.86      0.84      0.85        90\n",
      "weighted avg       0.86      0.84      0.85        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = 30\n",
    "svm_classifier = svm.SVC(C = C, #see slide 32 in week 4 handouts \n",
    "kernel = 'linear') #see slide 35 in week 4 handouts \n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = svm_classifier.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"C:\", C)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "662d8ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 40\n",
      "[[27  1  2]\n",
      " [ 0 24  6]\n",
      " [ 1  3 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93        30\n",
      "           1       0.86      0.80      0.83        30\n",
      "           2       0.76      0.87      0.81        30\n",
      "\n",
      "    accuracy                           0.86        90\n",
      "   macro avg       0.86      0.86      0.86        90\n",
      "weighted avg       0.86      0.86      0.86        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = 40\n",
    "svm_classifier = svm.SVC(C = C, #see slide 32 in week 4 handouts \n",
    "kernel = 'linear') #see slide 35 in week 4 handouts \n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = svm_classifier.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"C:\", C)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50442a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 50\n",
      "[[27  1  2]\n",
      " [ 0 24  6]\n",
      " [ 1  3 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93        30\n",
      "           1       0.86      0.80      0.83        30\n",
      "           2       0.76      0.87      0.81        30\n",
      "\n",
      "    accuracy                           0.86        90\n",
      "   macro avg       0.86      0.86      0.86        90\n",
      "weighted avg       0.86      0.86      0.86        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = 50\n",
    "svm_classifier = svm.SVC(C = C, #see slide 32 in week 4 handouts \n",
    "kernel = 'linear') #see slide 35 in week 4 handouts \n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = svm_classifier.predict(word_histograms) \n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"C:\", C)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a7a756",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ede4e138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 50\n",
      "[[22  0  8]\n",
      " [ 1 24  5]\n",
      " [ 3  1 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79        30\n",
      "           1       0.96      0.80      0.87        30\n",
      "           2       0.67      0.87      0.75        30\n",
      "\n",
      "    accuracy                           0.80        90\n",
      "   macro avg       0.82      0.80      0.80        90\n",
      "weighted avg       0.82      0.80      0.80        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 50\n",
    "adb_classifier = AdaBoostClassifier(n_estimators = n_estimators, #number of weak classifiers \n",
    "random_state = 0) \n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = adb_classifier.predict(word_histograms)\n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"n_estimators:\", n_estimators)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d127bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 100\n",
      "[[21  1  8]\n",
      " [ 0 25  5]\n",
      " [ 4  2 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76        30\n",
      "           1       0.89      0.83      0.86        30\n",
      "           2       0.65      0.80      0.72        30\n",
      "\n",
      "    accuracy                           0.78        90\n",
      "   macro avg       0.79      0.78      0.78        90\n",
      "weighted avg       0.79      0.78      0.78        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 100\n",
    "adb_classifier = AdaBoostClassifier(n_estimators = n_estimators, #number of weak classifiers \n",
    "random_state = 0) \n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = adb_classifier.predict(word_histograms)\n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"n_estimators:\", n_estimators)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b73b061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 150\n",
      "[[23  0  7]\n",
      " [ 0 25  5]\n",
      " [ 4  4 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81        30\n",
      "           1       0.86      0.83      0.85        30\n",
      "           2       0.65      0.73      0.69        30\n",
      "\n",
      "    accuracy                           0.78        90\n",
      "   macro avg       0.79      0.78      0.78        90\n",
      "weighted avg       0.79      0.78      0.78        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 150\n",
    "adb_classifier = AdaBoostClassifier(n_estimators = n_estimators, #number of weak classifiers \n",
    "random_state = 0) \n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = adb_classifier.predict(word_histograms)\n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"n_estimators:\", n_estimators)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d2a260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 200\n",
      "[[22  0  8]\n",
      " [ 0 25  5]\n",
      " [ 4  3 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79        30\n",
      "           1       0.89      0.83      0.86        30\n",
      "           2       0.64      0.77      0.70        30\n",
      "\n",
      "    accuracy                           0.78        90\n",
      "   macro avg       0.79      0.78      0.78        90\n",
      "weighted avg       0.79      0.78      0.78        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 200\n",
    "adb_classifier = AdaBoostClassifier(n_estimators = n_estimators, #number of weak classifiers \n",
    "random_state = 0) \n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = adb_classifier.predict(word_histograms)\n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"n_estimators:\", n_estimators)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "763aa8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 250\n",
      "[[21  1  8]\n",
      " [ 0 24  6]\n",
      " [ 4  4 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76        30\n",
      "           1       0.83      0.80      0.81        30\n",
      "           2       0.61      0.73      0.67        30\n",
      "\n",
      "    accuracy                           0.74        90\n",
      "   macro avg       0.76      0.74      0.75        90\n",
      "weighted avg       0.76      0.74      0.75        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 250\n",
    "adb_classifier = AdaBoostClassifier(n_estimators = n_estimators, #number of weak classifiers \n",
    "random_state = 0) \n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "predicted_food_labels = adb_classifier.predict(word_histograms)\n",
    "cm = confusion_matrix(test_food_labels, predicted_food_labels) \n",
    "print(\"n_estimators:\", n_estimators)\n",
    "print(cm) \n",
    "print(classification_report(test_food_labels, predicted_food_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
